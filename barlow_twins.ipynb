{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from AI_functions import resnet18, BarlowTwins, ImageCollateFunction,BarlowTwinsLoss,CellDataset,data_generator\n",
    "\n",
    "latent_dim=124\n",
    "epochs=200\n",
    "\n",
    "#Insert filepath for local files  FOR THIBAUT\n",
    "basepath = r\"C:\\Users\\Thibaut Goldsborough\\Documents\\Seth_BoneMarrow\\Data\\BoneMarrow_sample1\"\n",
    "readpath = basepath + \"\\\\Raw_Images\"\n",
    "outpath = basepath + \"\\\\Outputs\"\n",
    "file_prefix=\"\\\\sample1_\"\n",
    "maskpath=basepath+\"\\\\ExportedMasks\"\n",
    "image_dim=64 #Dim of the final images\n",
    "nuclear_channel=\"Ch7\"\n",
    "cellmask_channel=\"Ch1_mask\"\n",
    "df=pd.read_csv(outpath+\"\\\\cell_info.csv\")\n",
    "cell_names=df[\"Cell_ID\"].to_numpy()\n",
    "image_dict={}\n",
    "for cell_name in cell_names:\n",
    "    image_dict[cell_name]={}\n",
    "#Find Channels\n",
    "names=[]\n",
    "for entry in os.listdir(outpath): #Read all files\n",
    "    if os.path.isfile(os.path.join(outpath, entry)):\n",
    "        if entry!='image_ID.npy':\n",
    "            names.append(entry)\n",
    "channels=[name[:-4] for name in names if name[-4:]=='.npy']\n",
    "print(\"Channels found:\",channels)\n",
    "data_dict={}\n",
    "for channel in channels:\n",
    "    data_dict[channel]=np.load(outpath+\"\\\\\"+channel+'.npy')\n",
    "#Break up array\n",
    "for channel in data_dict:\n",
    "    dims=data_dict[channel].shape\n",
    "    n=dims[0]//image_dim\n",
    "    l=dims[1]//image_dim\n",
    "    index=0\n",
    "    for i in range(n):\n",
    "        for j in range(l):\n",
    "            img=data_dict[channel][i*image_dim:i*image_dim+image_dim,j*image_dim:j*image_dim+image_dim]\n",
    "            image_dict[cell_names[index]][channel]=img\n",
    "            index+=1\n",
    "\n",
    "def to_onehot(my_list):\n",
    "    return_list=[]\n",
    "    for i,elem in enumerate(my_list):\n",
    "        j=np.where(np.unique(labels)==elem)\n",
    "        return_list.append(np.zeros((len(np.unique(my_list)))))\n",
    "        return_list[-1][j]=1\n",
    "    return np.array(return_list)\n",
    "Channels=['Ch1']  #Channel to be fed to the NN\n",
    "\n",
    "images_with_index = []\n",
    "for image_i in image_dict:\n",
    "    image=cv.merge([image_dict[image_i][i] for i in Channels])\n",
    "    images_with_index.append((int(image_i),image))\n",
    "    \n",
    "images=np.array([image[1] for image in images_with_index])\n",
    "names=np.array([image[0] for image in images_with_index])\n",
    "labels=df['Cell_Type'].to_numpy()\n",
    "assert sum(names!=df['Cell_ID'].to_numpy()) ==0  #Check that the order has been preserved\n",
    "DNA_pos=df[\"DNA_pos\"].to_numpy()\n",
    "Touches_Boundary=df[\"Touches_boundary\"].to_numpy()\n",
    "labels=df['Cell_Type'].to_numpy()\n",
    "idx_to_keep=np.array(DNA_pos==1,dtype=int)+np.array(Touches_Boundary==0,dtype=int)+np.array(labels==0,dtype=int)+np.array(labels==2,dtype=int)==3  #keep dnapos, no touch boundarym APC and Other\n",
    "#Filter\n",
    "images=images[idx_to_keep]\n",
    "names=names[idx_to_keep]\n",
    "labels=labels[idx_to_keep]\n",
    "labels=to_onehot(labels)\n",
    "\n",
    "mini=int(round(abs(np.array(images).min()),0))\n",
    "images=images+abs(np.array(images).min())\n",
    "mean=np.array(images).mean()\n",
    "maxi=np.array(images).max()\n",
    "std=np.array(images).std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned=data_generator(images,labels,names,mini,train_test_split = 0.8,batch_size = 100)\n",
    "train_data,train_data1,train_labels,train_ID,test_data,batch_size,mean_loader,std_loader,sampler=returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToPILImage(),transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=180,fill=37),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize([64, 64]),\n",
    "\n",
    "   transforms.Normalize(mean=[mean_loader], std=[std_loader]),  # for grayscale images\n",
    "   ])\n",
    "   \n",
    "rotated = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.Normalize(mean=[mean_loader], std=[std_loader]),  # for grayscale images\n",
    "    transforms.RandomRotation(degrees=180,fill=0),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.Lambda(lambda x: x if 0.5>np.random.rand() else transforms.functional.invert(x)-1),\n",
    "    transforms.Lambda(lambda x: x *(1+0.2*np.random.randn()) ),\n",
    "   # transforms.Lambda(lambda x: x + (0.1**0.5)*torch.randn(64, 64) )\n",
    "    \n",
    "    ]) \n",
    "\n",
    "train_data = CellDataset(train_data1,train_labels,train_ID, rotated)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)#,sampler=sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imgs=next(iter(train_loader))\n",
    "plt.imshow(my_imgs[0][0][2][0])\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(my_imgs[0][1][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = CellDataset(train_data1,train_labels,train_ID, rotated)\n",
    "train_loader = DataLoader(train_data, batch_size=524,sampler=sampler)  #shuffle=True\n",
    "test_loader = DataLoader(test_data, batch_size=524, shuffle=True)\n",
    "\n",
    "def get_val():\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for (x0, x1), _ in test_loader:\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "        z0 = model(x0)\n",
    "        z1 = model(x1)\n",
    "        loss = criterion(z0, z1)\n",
    "        total_loss += loss.detach()\n",
    "\n",
    "    print(\"Validation Loss:\",int(total_loss / len(test_loader)))\n",
    "    return int(total_loss / len(test_loader))\n",
    "    \n",
    "def train():\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for (x0, x1), _ in train_loader:\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "        z0 = model(x0)\n",
    "        z1 = model(x1)\n",
    "        loss = criterion(z0, z1)\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "resnet = resnet18(num_classes=latent_dim,channel_num=len(Channels))\n",
    "backbone = resnet\n",
    "model = BarlowTwins(backbone,latent_dim)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "collate_fn = ImageCollateFunction(input_size=32)\n",
    "\n",
    "\n",
    "criterion = BarlowTwinsLoss(device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
    "\n",
    "print(\"Starting Training\")\n",
    "\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "for epoch in range(epochs):\n",
    "    avg_loss=train()\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "    train_losses.append(avg_loss)\n",
    "    val_losses.append(get_val())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses=[int(i.detach().cpu()) for i in train_losses]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.savefig(basepath+\"/Results/Loss\"+str(train_losses[-1])+\".png\",bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CellDataset(train_data1,train_labels,train_ID,rotated)\n",
    "train_loader = DataLoader(train_data, batch_size=124, shuffle=True)#,sampler=sampler)\n",
    "\n",
    "barlow=np.zeros((len(train_data1),latent_dim))\n",
    "names=np.zeros((len(train_data1)))\n",
    "labels=np.zeros((len(train_data1)))\n",
    "i=0\n",
    "for (x0, x1), Y in train_loader:\n",
    "    x0 = x0.to(device)\n",
    "    x1 = x1.to(device)\n",
    "    latents=model.backbone(x0).detach().cpu().numpy()\n",
    "    names[i:i+len(latents)]=Y[:,1]\n",
    "    labels[i:i+len(latents)]=Y[:,0]\n",
    "    barlow[i:i+len(latents)]=latents\n",
    "    i+=len(latents)\n",
    "    print(i,len(train_data1))\n",
    "\n",
    "df3=pd.DataFrame(barlow)\n",
    "df3[\"Cell_ID\"]=names\n",
    "df3.to_csv(basepath+\"/Results/Barlow_latents\"+str(train_losses[-1])+\".csv\", index = False, header=True)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e92283253362575e1b2577a58171a1def071c2d4840c376515c402fb1735d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
