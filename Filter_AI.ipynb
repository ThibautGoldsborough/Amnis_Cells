{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72658802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from Helper_functions import load_dict\n",
    "from AI_functions import resnet18,CellDataset_supervised,data_generator\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4692076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RETINA_1_2\n",
    "#Debris and Doublets:\n",
    "OTHER=[922, 6342, 8158, 8703, 5524, 902, 9760, 8737, 55404, 841, 851, 5277, 5829, 7777, 51964, 9823, 54418, 54239, 6156, 8487, 5415, 50438, 670, 49993, 55353, 7878, 50196, 856, 9421, 52299, 54295, 54603, 54704, 50189, 55290, 7164, 705, 7204, 53440, 55283, 7292, 6151]\n",
    "SINGLES=[52596, 7186, 55477, 6624, 51312, 7344, 54918, 5978, 53696, 807, 8336, 8475, 55349, 5243, 55714, 8329, 51652, 51648, 50895, 9536, 55141, 50406, 5208, 51799, 9845, 50229, 6622, 8199, 7800, 51898, 9733, 52683, 7414, 49884, 53164, 9868, 7998, 53455, 55694, 9598, 52251, 53414, 7549, 50199, 8152, 5265, 49955, 50998, 50929, 52043]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS=[\"BoneMarrow_sample1\"]#,\"Retina_1_2\",\"Colon\",\"Choroid\"]\n",
    "DATASET=\"Retina_0_0\"\n",
    "basepath = r\"C:\\Users\\Thibaut Goldsborough\\Documents\\Seth_BoneMarrow\\Data\\\\\" +DATASET\n",
    "outpath = basepath + \"\\\\Outputs\"\n",
    "image_dim=64 #Dim of the final images\n",
    "nuclear_channel=\"Ch7\"\n",
    "cellmask_channel=\"Ch1_mask\"\n",
    "df=pd.read_csv(outpath+\"\\\\cell_info1.csv\")\n",
    "cell_names=df[\"Cell_ID\"].to_numpy()\n",
    "Prediction_Channels=['Ch07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c6172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(outpath+\"\\\\cell_info1.csv\")\n",
    "# df_labels=pd.read_csv(outpath+\"\\\\labeled_cells_final.csv\")\n",
    "# df_labels=df_labels.rename(columns={\"cell_id\":\"Cell_ID\"})\n",
    "# df_labels=df_labels[[\"Cell_ID\",\"label\"]]\n",
    "# df_merged=pd.merge(df,df_labels,left_on=\"Cell_ID\",right_on=\"Cell_ID\",how='left')\n",
    "# df_merged.to_csv(outpath+\"\\\\cell_info1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5828c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict=load_dict(outpath,cell_names,image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_dict[39010]['Ch1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUGS=[]\n",
    "for image in image_dict:\n",
    "    for i in image_dict[image]:\n",
    "      #  print(i)\n",
    "        try: \n",
    "            if i==None:\n",
    "                BUGS.append(image)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(len(BUGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67667505",
   "metadata": {},
   "outputs": [],
   "source": [
    "Channels=['Ch1']  #Channel to be fed to the NN\n",
    "images_with_index = []\n",
    "\n",
    "for image_i in image_dict:\n",
    "    #print(image_dict[image_i].keys())\n",
    "    if len(image_dict[image_i].keys())>=len(Channels):\n",
    "        image=cv.merge([image_dict[image_i][i] for i in Channels])\n",
    "        images_with_index.append((int(image_i),image))\n",
    "    else:\n",
    "        print(image_i)\n",
    "    \n",
    "images=np.array([image[1] for image in images_with_index])\n",
    "names=np.array([image[0] for image in images_with_index])\n",
    "assert sum(names!=df['Cell_ID'].to_numpy()) ==0  #Check that the order has been preserved\n",
    "DNA_pos=df[\"DNA_pos\"].to_numpy()\n",
    "Touches_Boundary=df[\"Touches_boundary\"].to_numpy()\n",
    "labels=df['label'].to_numpy().copy()\n",
    "idx_nan=np.array([i is not np.nan for i in labels],dtype=int)\n",
    "labels[labels=='d']='f'\n",
    "labels[labels=='f']=0\n",
    "labels[labels=='s']=1\n",
    "convert={'0':[0,1],'1':[1,0]}\n",
    "\n",
    "labels1=[]\n",
    "for i in labels:\n",
    "    if i is not np.nan:\n",
    "        labels1.append(convert[str(i)])\n",
    "    else:\n",
    "        labels1.append([10,10])  #Doesnt matter\n",
    "\n",
    "labels1=np.array(labels1,dtype=object)\n",
    "\n",
    "\n",
    "Thresh=50\n",
    "idx_to_keep=idx_nan+np.array(Touches_Boundary==0,dtype=int)+np.array(df[\"Gradient RMS_M01_Ch01\"]>Thresh,dtype=int)==3 #keep dnapos, no touch boundarym APC and Other\n",
    "#Filter\n",
    "images=images[idx_to_keep]\n",
    "names=names[idx_to_keep]\n",
    "labels=labels1[idx_to_keep]\n",
    "#labels=np.concatenate(labels,axis=0).reshape(len(labels),2)\n",
    "\n",
    "mini=int(round(abs(np.array(images).min()),0))\n",
    "images=images+abs(np.array(images).min())\n",
    "mean=np.array(images).mean()\n",
    "maxi=np.array(images).max()\n",
    "std=np.array(images).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[names==39691][0])\n",
    "labels[names==113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels1[idx_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Cell_ID\"]==10007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb73edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=8\n",
    "plt.imshow(images[i])\n",
    "print(names[i])\n",
    "print(labels[i])\n",
    "df[df[\"Cell_ID\"]==names[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59984b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned=data_generator(images,labels,names,mini,train_test_split = 0.8,batch_size = 100,sample=False)\n",
    "train,test,batch_size,mean_loader,std_loader=returned\n",
    "[train_data,train_data1,train_labels,train_ID]=train\n",
    "[test_data,test_data1,test_labels,test_ID]=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d84ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3): \n",
    "    plt.imshow(images[i])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToPILImage(),transforms.RandomHorizontalFlip(p=0.5),transforms.RandomVerticalFlip(p=0.5),transforms.RandomRotation(degrees=18,fill=mini),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_loader,std_loader)  \n",
    "])\n",
    "\n",
    "transform_validation = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_loader,std_loader)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a61fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data1[train_ID==39691][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CellDataset_supervised(train_data1,train_labels,train_ID, transform_train)\n",
    "test_data = CellDataset_supervised(test_data1,test_labels, test_ID,transform_validation)\n",
    "\n",
    "# from torch.utils.data.sampler import WeightedRandomSampler\n",
    "# print(np.max(train_labels))\n",
    "# def sampler_f(x):\n",
    "#     return ((x)+abs(np.min(train_labels)))**3+1\n",
    "# weights=sampler_f(train_labels)\n",
    "# #weights/=np.sum(weights)\n",
    "# torch.tensor(weights)\n",
    "# sampler = WeightedRandomSampler(weights.T[0], len(weights))\n",
    "\n",
    "\n",
    "#Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,shuffle=True)#False,sampler=sampler)\n",
    "validation_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in validation_loader:\n",
    "    plt.imshow(i[0][0][0])\n",
    "    plt.show()\n",
    "    print(i[1][0])\n",
    "    print(i[2][0])\n",
    "   # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(train_loader,outpath+\"\\\\\"+DATASET+\"_train.pth\")\n",
    "#torch.save(validation_loader,outpath+\"\\\\\"+DATASET+\"_validation.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(next(iter(train_loader))[0][0][0],vmin=-10,vmax=10)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(next(iter(train_loader))[0][0][0],vmin=-10,vmax=10)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(NN, device, dataloader, loss_fn, optimizer,noise_factor=0):\n",
    "    NN.train()\n",
    "    train_loss = []\n",
    "    for image_batch,labels_batch,_ in dataloader: \n",
    "        image_noisy = image_batch\n",
    "        image_batch = image_noisy.to(device)\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        output = NN(image_batch)\n",
    "        loss = loss_fn(labels_batch,output)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validation_epoch(NN, device, dataloader, loss_fn):\n",
    "    NN.eval()\n",
    "    val_loss=[]\n",
    "    with torch.no_grad(): \n",
    "        for image_batch,labels_batch,ID_batch in dataloader:\n",
    "            image_batch = image_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "            output = NN(image_batch)\n",
    "            loss = loss_fn(labels_batch,output,)\n",
    "            val_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61214c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in validation_loader:\n",
    "    plt.imshow(i[0][0][0])\n",
    "    plt.show()\n",
    "    print(i[1][0])\n",
    "    print(i[2][0])\n",
    "   # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=20\n",
    "lr=1e-3\n",
    "num_classes=2\n",
    "\n",
    "ConvNet_simple=resnet18(channel_num=len(Channels),num_classes=num_classes)\n",
    "#ConvNet_simple=Trained_model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ConvNet_simple.to(device)\n",
    "loss_dict={\"L1\":nn.L1Loss(),\"MSE\":nn.MSELoss()}\n",
    "\n",
    "loss_fn = loss_dict[\"L1\"]\n",
    "\n",
    "#optimizer = optim.Adam(ConvNet_simple.parameters(), lr = lr) \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, ConvNet_simple.parameters()),lr=lr)\n",
    "\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "\n",
    "counter=0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = train_epoch(ConvNet_simple,device,train_loader,loss_fn,optimizer)\n",
    "    val_loss = validation_epoch(ConvNet_simple,device,validation_loader,loss_fn)\n",
    "\n",
    "\n",
    "    print('\\n EPOCH',epoch+1,' \\t train loss',train_loss,' \\t val loss',val_loss)\n",
    "    diz_loss['train_loss'].append(train_loss)\n",
    "    diz_loss['val_loss'].append(val_loss)\n",
    "\n",
    "\n",
    "#_ = loss_over_epochs(diz_loss,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86fa8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions=np.zeros((len(test_data1),num_classes))\n",
    "names=np.zeros((len(test_data1)))\n",
    "labels=np.zeros((len(test_data1),num_classes))\n",
    "i=0\n",
    "ConvNet_simple.eval()\n",
    "with torch.no_grad():\n",
    "    for X, Y,ID in validation_loader:\n",
    "        X = X.to(device)\n",
    "        latents=ConvNet_simple(X).detach().cpu().numpy()\n",
    "        labels[i:i+len(latents)]=Y\n",
    "        names[i:i+len(latents)]=ID\n",
    "        predictions[i:i+len(latents)]=latents\n",
    "        i+=len(latents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "a='[\"a\",\"b\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ae471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e92283253362575e1b2577a58171a1def071c2d4840c376515c402fb1735d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
