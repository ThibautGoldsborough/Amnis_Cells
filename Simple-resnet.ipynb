{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from AI_functions import resnet18, CellDataset, data_generator\n",
    "from Helper_functions import to_onehot\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "latent_dim=124\n",
    "epochs=200\n",
    "\n",
    "#Insert filepath for local files  FOR THIBAUT\n",
    "basepath = r\"C:\\Users\\Thibaut Goldsborough\\Documents\\Seth_BoneMarrow\\Data\\BoneMarrow_sample1\"\n",
    "readpath = basepath + \"\\\\Raw_Images\"\n",
    "outpath = basepath + \"\\\\Outputs\"\n",
    "file_prefix=\"\\\\sample1_\"\n",
    "maskpath=basepath+\"\\\\ExportedMasks\"\n",
    "image_dim=64 #Dim of the final images\n",
    "nuclear_channel=\"Ch7\"\n",
    "cellmask_channel=\"Ch1_mask\"\n",
    "df=pd.read_csv(outpath+\"\\\\cell_info.csv\")\n",
    "cell_names=df[\"Cell_ID\"].to_numpy()\n",
    "image_dict={}\n",
    "for cell_name in cell_names:\n",
    "    image_dict[cell_name]={}\n",
    "#Find Channels\n",
    "names=[]\n",
    "for entry in os.listdir(outpath): #Read all files\n",
    "    if os.path.isfile(os.path.join(outpath, entry)):\n",
    "        if entry!='image_ID.npy':\n",
    "            names.append(entry)\n",
    "channels=[name[:-4] for name in names if name[-4:]=='.npy']\n",
    "print(\"Channels found:\",channels)\n",
    "data_dict={}\n",
    "for channel in channels:\n",
    "    data_dict[channel]=np.load(outpath+\"\\\\\"+channel+'.npy')\n",
    "#Break up array\n",
    "for channel in data_dict:\n",
    "    dims=data_dict[channel].shape\n",
    "    n=dims[0]//image_dim\n",
    "    l=dims[1]//image_dim\n",
    "    index=0\n",
    "    for i in range(n):\n",
    "        for j in range(l):\n",
    "            img=data_dict[channel][i*image_dim:i*image_dim+image_dim,j*image_dim:j*image_dim+image_dim]\n",
    "            image_dict[cell_names[index]][channel]=img\n",
    "            index+=1\n",
    "\n",
    "\n",
    "Channels=['Ch1']  #Channel to be fed to the NN\n",
    "\n",
    "images_with_index = []\n",
    "for image_i in image_dict:\n",
    "    image=cv.merge([image_dict[image_i][i] for i in Channels])\n",
    "    images_with_index.append((int(image_i),image))\n",
    "    \n",
    "images=np.array([image[1] for image in images_with_index])\n",
    "names=np.array([image[0] for image in images_with_index])\n",
    "labels=df['Cell_Type'].to_numpy()\n",
    "assert sum(names!=df['Cell_ID'].to_numpy()) ==0  #Check that the order has been preserved\n",
    "DNA_pos=df[\"DNA_pos\"].to_numpy()\n",
    "Touches_Boundary=df[\"Touches_boundary\"].to_numpy()\n",
    "labels=df['Cell_Type'].to_numpy()\n",
    "idx_to_keep=np.array(DNA_pos==1,dtype=int)+np.array(Touches_Boundary==0,dtype=int)+np.array(labels==0,dtype=int)+np.array(labels==2,dtype=int)==3  #keep dnapos, no touch boundarym APC and Other\n",
    "#Filter\n",
    "images=images[idx_to_keep]\n",
    "names=names[idx_to_keep]\n",
    "labels=labels[idx_to_keep]\n",
    "labels=to_onehot(labels)\n",
    "\n",
    "mini=int(round(abs(np.array(images).min()),0))\n",
    "images=images+abs(np.array(images).min())\n",
    "mean=np.array(images).mean()\n",
    "maxi=np.array(images).max()\n",
    "std=np.array(images).std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=data_generator(images,labels,names,mini,train_test_split = 0.8,batch_size = 100,sampler=False)\n",
    "train_data,train_data1,train_labels,train_ID,test_data,batch_size,mean_loader,std_loader=r\n",
    "NN=resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #Oversampling\n",
    "#Transform data into tensors, normalize images\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToPILImage(),transforms.RandomHorizontalFlip(p=0.5),transforms.RandomVerticalFlip(p=0.5),transforms.RandomRotation(degrees=180,fill=mini),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_loader,std_loader)  \n",
    "])\n",
    "\n",
    "#Transform data into tensors, normalize images\n",
    "transform_validation = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_loader,std_loader)  \n",
    "])\n",
    "\n",
    "\n",
    "counts=np.bincount(np.argmax(train_labels,axis=1))\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[np.argmax(train_labels,axis=1)]\n",
    "sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "train_data = CellDataset(train_data,train_labels, transform_train)\n",
    "validation_data = CellDataset(validation_data,validation_labels, transform_validation)\n",
    "\n",
    "\n",
    "#Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False,sampler=sampler)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ConvNet_simple=model\n",
    "ConvNet_simple.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(ConvNet_simple.parameters(), lr = lr) \n",
    "\n",
    "diz_loss = {'train_loss':[],'val_loss':[],'train_acc':[],'val_acc':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss,train_acc = train_epoch(ConvNet_simple,device,train_loader,loss_fn,optimizer)\n",
    "    val_loss,val_acc = validation_epoch(ConvNet_simple,device,validation_loader,loss_fn)\n",
    "    \n",
    "    print('\\n EPOCH',epoch+1,' \\t train loss',train_loss,' \\t val loss',val_loss,'\\t train acc',train_acc,'\\t val acc',val_acc)\n",
    "    diz_loss['train_loss'].append(train_loss)\n",
    "    diz_loss['val_loss'].append(val_loss)\n",
    "    diz_loss['train_acc'].append(train_acc)\n",
    "    diz_loss['val_acc'].append(val_acc)\n",
    "\n",
    "_ = loss_over_epochs(diz_loss,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ebb947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get information about CPU/GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(image,noise_factor):\n",
    "    return image+ noise_factor * torch.randn(*image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and evaluate model\n",
    "### Training function\n",
    "def train_epoch(NN, device, dataloader, loss_fn, optimizer,noise_factor=0):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    NN.train()\n",
    "    train_loss = []\n",
    "    total=0\n",
    "    correct=0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch,labels_batch in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        image_noisy = add_noise(image_batch,noise_factor) \n",
    "        image_batch = image_noisy.to(device)\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        output = NN(image_batch)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(output,labels_batch)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        total+=labels_batch.size(0)\n",
    "\n",
    "        output=output.detach().cpu().numpy()\n",
    "        labels=labels_batch.detach().cpu().numpy()\n",
    "\n",
    "        correct+=np.sum(np.argmax(output,axis=1)==np.argmax(labels,axis=1))\n",
    "\n",
    "\n",
    "    accuracy=100 * correct / total\n",
    "\n",
    "    return np.mean(train_loss),accuracy\n",
    "\n",
    "\n",
    "### validationing function\n",
    "def validation_epoch(NN, device, dataloader, loss_fn):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    NN.eval()\n",
    "    total=0\n",
    "    correct=0\n",
    "    val_loss=[]\n",
    "\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "\n",
    "        for image_batch,labels_batch in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "            output = NN(image_batch)\n",
    "            loss = loss_fn(output,labels_batch)\n",
    "\n",
    "            total+=labels_batch.size(0)\n",
    "\n",
    "            output=output.detach().cpu().numpy()\n",
    "            labels=labels_batch.detach().cpu().numpy()\n",
    "\n",
    "            correct+=np.sum(np.argmax(output,axis=1)==np.argmax(labels,axis=1))\n",
    "\n",
    "            val_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    accuracy=100 * correct / total\n",
    "    return np.mean(val_loss),accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ba1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses at the end of training\n",
    "def loss_over_epochs(diz_loss,num_epochs):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.semilogy(diz_loss['train_loss'], label='Train')\n",
    "    plt.semilogy(diz_loss['val_loss'], label='Valid')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title('Loss over ' + str(num_epochs) + ' epochs')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(diz_loss['train_acc'], label='Train')\n",
    "    plt.plot(diz_loss['val_acc'], label='Valid')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title('Loss over ' + str(num_epochs) + ' epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(next(iter(train_data1)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_NN(train_data=train_data1,validation_data=validation_data1,model=resnet18(False,True),str_model='resnet18',batch_size=20,num_epochs = 25,lr=0.001):\n",
    "\n",
    "\n",
    "    return diz_loss,str_model,ConvNet_simple,validation_loader,train_loader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(NN,validation_loader):\n",
    "    y_trues=[]\n",
    "    y_preds=[]\n",
    "\n",
    "\n",
    "    #validation_loader = DataLoader(validation_data, batch_size=int(len(validation_data)/10), shuffle=False)\n",
    "\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "\n",
    "        for image_batch,labels_batch in validation_loader:\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "\n",
    "            labels=labels_batch.to(device).detach().cpu().numpy()\n",
    "            y_true=np.argmax(labels,axis=1)\n",
    "\n",
    "            output=NN(image_batch).detach().cpu().numpy()\n",
    "            y_pred=np.argmax(output,axis=1)\n",
    "\n",
    "            y_trues.extend(list(y_true))\n",
    "            y_preds.extend(list(y_pred))     \n",
    "\n",
    "\n",
    "\n",
    "    conf=confusion_matrix(y_trues, y_preds,labels=cell_types)\n",
    "\n",
    "    return y_trues,y_preds,conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argsort(df['Cell_Type'].unique())\n",
    "df['Cell_Type_str'].unique()[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8fa824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53285d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['Cell_Type_str'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#from plotcm import plot_confusion_matrix\n",
    "#plt.figure(figsize=(5,5),dpi=100)\n",
    "##plot_confusion_matrix(conf, [\"Singlet\",\"Doublet\",\"Debris\"],normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3281a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model outputs\n",
    "\n",
    "def save_output(diz_loss,str_model,y_trues,y_preds,conf):\n",
    "    name=str_model\n",
    "    mean_acc=round(np.mean(diz_loss['val_acc'][-5:]),2)\n",
    "    new_dir=basepath+\"\\\\Results\\\\\"+name+'_'+str(mean_acc)\n",
    "\n",
    "    dir=new_dir\n",
    "    count=1\n",
    "    while os.path.exists(dir):\n",
    "        dir=new_dir+'('+str(count)+')'\n",
    "        count+=1\n",
    "\n",
    "    new_dir=dir\n",
    "    os.mkdir(new_dir)\n",
    "\n",
    "    destination1=new_dir+'\\\\Loss.csv'\n",
    "    destination2=new_dir+'\\\\Predictions.csv'\n",
    "    destination3=new_dir+'\\\\Confusion_mat.png'\n",
    "\n",
    "    df1 = pd.DataFrame.from_dict(diz_loss)\n",
    "    df1.to_csv (destination1, index = False, header=True)\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['Cell_ID']  = validation_ID\n",
    "    df1['Prediction']  = y_preds\n",
    "    df1['Ground Truth']=y_trues\n",
    "    df1.to_csv (destination2, index = False, header=True)\n",
    "\n",
    "    fig=plt.figure(figsize=(5,5),dpi=150)\n",
    "    a=np.argsort(df['Cell_Type'].unique())\n",
    "    list_str=df['Cell_Type_str'].unique()[a]\n",
    "    list_str=['Other','APC']\n",
    "    plot_confusion_matrix(conf, list_str,normalize=True)\n",
    "    fig.savefig(destination3,bbox_inches='tight', dpi=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_loss,str_model,NN,validation_loader,train_loader=Run_NN(model=resnet18(),str_model='Resnet18',num_epochs=1,polar=False,batch_size=20)\n",
    "y_trues,y_preds,conf=get_preds(NN,validation_loader)\n",
    "save_output(diz_loss,str_model,y_trues,y_preds,conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues,y_preds,conf=get_preds(NN,validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35177951",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues,y_preds,conf=get_preds(NN,validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types=[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5faa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0][5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902ac6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8067ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cell_OD\"]=[1 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72658802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e92283253362575e1b2577a58171a1def071c2d4840c376515c402fb1735d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
